# -*- coding: utf-8 -*-
"""Evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C3ayskUwrXfKGhyySzO_y9N3FO8dHbZT
"""

!pip install SpeechRecognition
!pip install jiwer
!pip install scikit-learn
!pip install pydub
!pip install python-Levenshtein

#pip install jiwer python-Levenshtein
!pip install fuzzywuzzy
!pip install textstat

import os
folder_path = "PATH TO YOUR DIRECTORY"
print(os.listdir(folder_path))

folder_path = "PATH TO YOUR DIRECTORY"
print(os.listdir(folder_path))

import os
import speech_recognition as sr
from pydub import AudioSegment
from jiwer import wer
import Levenshtein
import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from nltk.translate.bleu_score import sentence_bleu
from sklearn.feature_extraction.text import CountVectorizer
from sentence_transformers import SentenceTransformer

# Folders
stammered_audio_folder = "PATH TO YOUR DIRECTORY"
fluent_audio_folder = "PATH TO YOUR DIRECTORY"
output_folder = "PATH TO YOUR DIRECTORY"
os.makedirs(output_folder, exist_ok=True)

recognizer = sr.Recognizer()

# Transcribe audio
def transcribe_audio(audio_path):
    try:
        if audio_path.endswith(".mp3"):
            audio = AudioSegment.from_mp3(audio_path)
            temp_wav_path = audio_path.replace(".mp3", "_temp.wav")
            audio.export(temp_wav_path, format="wav")
            audio_path = temp_wav_path

        with sr.AudioFile(audio_path) as source:
            audio_data = recognizer.record(source)
            text = recognizer.recognize_google(audio_data)
            return text.strip().lower()
    except sr.UnknownValueError:
        return "[Unrecognized Speech]"
    except sr.RequestError as e:
        return f"[API Request Error: {e}]"
    except Exception as e:
        return f"[Error: {e}]"

# Calculate evaluation metrics
def compute_metrics(ref, hyp):
    if "[error" in ref or "[error" in hyp or "[unrecognized" in ref or "[unrecognized" in hyp:
        return {"wer": "N/A", "levenshtein": "N/A", "cosine_similarity": "N/A", "bleu_score": "N/A", "jaccard_similarity": "N/A", "semantic_similarity": "N/A"}

    wer_score = round(wer(ref, hyp), 4)
    lev_distance = Levenshtein.distance(ref, hyp)

    vectorizer = CountVectorizer().fit_transform([ref, hyp])
    cosine_sim = cosine_similarity(vectorizer[0:1], vectorizer[1:2]).flatten()[0]

    bleu_score = sentence_bleu([ref.split()], hyp.split())

    ref_set = set(ref.split())
    hyp_set = set(hyp.split())
    jaccard_sim = len(ref_set & hyp_set) / len(ref_set | hyp_set)

    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')
    ref_embedding = model.encode([ref])[0]
    hyp_embedding = model.encode([hyp])[0]
    semantic_sim = cosine_similarity([ref_embedding], [hyp_embedding]).flatten()[0]

    return {
        "wer": wer_score,
        "levenshtein": lev_distance,
        "cosine_similarity": cosine_sim,
        "bleu_score": bleu_score,
        "jaccard_similarity": jaccard_sim,
        "semantic_similarity": semantic_sim
    }

# Evaluate only matching files
def evaluate_audio_files():
    results = []

    # Get base filenames from each folder
    stammered_basenames = {
        os.path.splitext(f)[0]: os.path.join(stammered_audio_folder, f)
        for f in os.listdir(stammered_audio_folder) if f.endswith(".wav")
    }

    fluent_basenames = {
        os.path.splitext(f.replace("_fluent", ""))[0]: os.path.join(fluent_audio_folder, f)
        for f in os.listdir(fluent_audio_folder) if f.endswith("_fluent.mp3")
    }

    # Find common basenames
    matching_basenames = sorted(set(stammered_basenames.keys()) & set(fluent_basenames.keys()))

    print(f"\nüîç Found {len(matching_basenames)} matching file pairs.")

    for base_name in matching_basenames:
        stammered_path = stammered_basenames[base_name]
        fluent_path = fluent_basenames[base_name]

        print(f"\nüéß Evaluating: {base_name}")
        stammered_text = transcribe_audio(stammered_path)
        fluent_text = transcribe_audio(fluent_path)

        metrics = compute_metrics(fluent_text, stammered_text)

        results.append({
            "File": base_name,
            "WER": metrics["wer"],
            "Levenshtein Distance": metrics["levenshtein"],
            "Cosine Similarity": metrics["cosine_similarity"],
            "BLEU Score": metrics["bleu_score"],
            "Jaccard Similarity": metrics["jaccard_similarity"],
            "Semantic Similarity": metrics["semantic_similarity"],
            "Fluent Text": fluent_text,
            "Stammered Text": stammered_text
        })

        # Save text output per file
        output_file = os.path.join(output_folder, f"evaluation_{base_name}.txt")
        with open(output_file, "w") as f:
            f.write(f"File: {base_name}\n")
            f.write(f"Stammered Text: {stammered_text}\n")
            f.write(f"Fluent Text: {fluent_text}\n\n")
            f.write(f"üîé Metrics:\n")
            f.write(f"WER: {metrics['wer']}\n")
            f.write(f"Levenshtein Distance: {metrics['levenshtein']}\n")
            f.write(f"Cosine Similarity: {metrics['cosine_similarity']}\n")
            f.write(f"BLEU Score: {metrics['bleu_score']}\n")
            f.write(f"Jaccard Similarity: {metrics['jaccard_similarity']}\n")
            f.write(f"Semantic Similarity: {metrics['semantic_similarity']}\n")

        print(f"‚úÖ Saved results for: {base_name} (WER={metrics['wer']})")

    # Save all to CSV
    df = pd.DataFrame(results)
    df.to_csv(os.path.join(output_folder, "evaluation_results.csv"), index=False)
    print("\nüìä All evaluations saved to evaluation_results.csv")

# Run evaluation
evaluate_audio_files()