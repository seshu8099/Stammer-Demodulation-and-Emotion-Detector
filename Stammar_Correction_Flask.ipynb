{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGxgkuxgpWNI"
      },
      "outputs": [],
      "source": [
        "!./ngrok authtoken <Your Token>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install pydub\n",
        "!pip install gTTS\n",
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B0zbJOqpmUi",
        "outputId": "accdbac3-07c0-4100-d914-59d8e2697083"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=0.8->flask-ngrok) (3.0.2)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTS) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2025.1.31)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.4\n",
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.2-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.13.1)\n",
            "Downloading speechrecognition-3.14.2-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install Flask torch librosa transformers gtts moviepy pyngrok\n",
        "import os\n",
        "from flask import Flask, request, render_template_string, send_from_directory\n",
        "from moviepy.editor import VideoFileClip\n",
        "import torch\n",
        "import librosa\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "from gtts import gTTS\n",
        "from pyngrok import ngrok  # REPLACEMENT for flask_ngrok\n",
        "\n",
        "# Set folders\n",
        "UPLOAD_FOLDER = 'uploads'\n",
        "OUTPUT_FOLDER = 'outputs'\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "\n",
        "# Load Whisper model\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "model.eval()\n",
        "\n",
        "# Transcribe function\n",
        "def transcribe_audio(audio_file_path):\n",
        "    audio_input, _ = librosa.load(audio_file_path, sr=16000, mono=True)\n",
        "    inputs = processor(audio_input, return_tensors=\"pt\", sampling_rate=16000)\n",
        "    with torch.no_grad():\n",
        "        predicted_ids = model.generate(inputs[\"input_features\"], max_length=1024)\n",
        "    transcription = processor.decode(predicted_ids[0], skip_special_tokens=True)\n",
        "    return transcription\n",
        "\n",
        "# Dummy emotion detection\n",
        "def detect_emotion(transcribed_text):\n",
        "    emotions = [\"neutral\", \"happy\", \"sad\", \"angry\"]\n",
        "    return \"neutral\", 0.9  # Placeholder\n",
        "\n",
        "# Dummy stammer severity\n",
        "def detect_stammer_severity(audio_file_path):\n",
        "    return \"mild\"  # Placeholder\n",
        "\n",
        "# Convert to fluent audio\n",
        "def convert_to_fluent_audio(text, wav_file_path):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    mp3_file_path = os.path.join(OUTPUT_FOLDER, os.path.basename(wav_file_path).replace(\".wav\", \"_fluent.mp3\"))\n",
        "    tts.save(mp3_file_path)\n",
        "    return mp3_file_path\n",
        "\n",
        "# Home route\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template_string('''\n",
        "        <!doctype html>\n",
        "        <html>\n",
        "        <head>\n",
        "            <title>Speech Analyzer</title>\n",
        "            <style>\n",
        "                body { font-family: Arial; padding: 20px; }\n",
        "                .container { max-width: 600px; margin: auto; }\n",
        "                input[type=\"file\"] { margin: 10px 0; }\n",
        "                .btn { padding: 10px 15px; background-color: #4CAF50; color: white; border: none; cursor: pointer; }\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <div class=\"container\">\n",
        "                <h2>Upload Audio/Video for Analysis</h2>\n",
        "                <form action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "                    <input type=\"file\" name=\"file\" required>\n",
        "                    <button type=\"submit\" class=\"btn\">Upload</button>\n",
        "                </form>\n",
        "            </div>\n",
        "        </body>\n",
        "        </html>\n",
        "    ''')\n",
        "\n",
        "# Serve output files\n",
        "@app.route('/outputs/<filename>')\n",
        "def download_file(filename):\n",
        "    return send_from_directory(OUTPUT_FOLDER, filename)\n",
        "\n",
        "# Upload route\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_audio():\n",
        "    if 'file' not in request.files:\n",
        "        return \"No file uploaded\"\n",
        "\n",
        "    file = request.files['file']\n",
        "    filename = file.filename\n",
        "    file_path = os.path.join(UPLOAD_FOLDER, filename)\n",
        "    file.save(file_path)\n",
        "\n",
        "    # Convert video to audio if needed\n",
        "    if filename.lower().endswith(('.mp4', '.mkv', '.avi', '.mov')):\n",
        "        audio_path = os.path.join(UPLOAD_FOLDER, filename.rsplit('.', 1)[0] + \".wav\")\n",
        "        clip = VideoFileClip(file_path)\n",
        "        clip.audio.write_audiofile(audio_path)\n",
        "        file_path = audio_path\n",
        "\n",
        "    # Ensure file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        return \"File conversion failed.\"\n",
        "\n",
        "    # Transcribe and analyze\n",
        "    audio_text = transcribe_audio(file_path)\n",
        "    emotion, score = detect_emotion(audio_text)\n",
        "    severity = detect_stammer_severity(file_path)\n",
        "    fluent_audio = convert_to_fluent_audio(audio_text, file_path)\n",
        "    fluent_audio_filename = os.path.basename(fluent_audio)\n",
        "\n",
        "    return render_template_string('''\n",
        "        <!doctype html>\n",
        "        <html>\n",
        "        <head>\n",
        "            <title>Results</title>\n",
        "            <style>\n",
        "                body { font-family: Arial; padding: 20px; }\n",
        "                .container { max-width: 700px; margin: auto; }\n",
        "                .btn { padding: 10px 15px; background-color: #008CBA; color: white; border: none; text-decoration: none; }\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <div class=\"container\">\n",
        "                <h2>Transcription Result</h2>\n",
        "                <p><strong>Text:</strong> {{ audio_text }}</p>\n",
        "                <p><strong>Detected Emotion:</strong> {{ emotion }} (Confidence: {{ confidence }})</p>\n",
        "                <p><strong>Stammer Severity:</strong> {{ severity }}</p>\n",
        "                <p><strong>Fluent Audio:</strong></p>\n",
        "                <audio controls>\n",
        "                    <source src=\"/outputs/{{ fluent_audio_filename }}\" type=\"audio/mpeg\">\n",
        "                    Your browser does not support the audio element.\n",
        "                </audio><br><br>\n",
        "                <a href=\"/outputs/{{ fluent_audio_filename }}\" class=\"btn\" download>Download Fluent Audio</a>\n",
        "            </div>\n",
        "        </body>\n",
        "        </html>\n",
        "    ''', audio_text=audio_text, emotion=emotion, confidence=round(score, 2),\n",
        "         severity=severity, fluent_audio_filename=fluent_audio_filename)\n",
        "\n",
        "# Start the app and ngrok tunnel\n",
        "if __name__ == '__main__':\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"\\n * ngrok tunnel available at: {public_url.public_url}\\n\")\n",
        "    app.run()\n"
      ],
      "metadata": {
        "id": "o2o53RdgprND"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}